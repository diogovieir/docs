---
title: ChunkCount
description: Split text based on a count pattern
---

# ChunkCount: Text Splitting by Count Pattern

Text splitting based on a count pattern uses three main concepts: **count unit**, **threshold**, and **overlap**. This technique is useful for segmenting text into smaller parts, especially for processing or analysis.

---

## Key Concepts

### Count Unit (`count_unit`)

- The element that will be counted in the text.
- It can be:
  - A specific word, such as `"chapter"`.
  - A special character, such as `"\n"`.
  - A more complex pattern defined by regular expressions, such as `"\."` for sentences ending with a period.

### Threshold (`count_threshold`)

- Defines the minimum number of times the **count unit** must appear before creating a split in the text.
- **Example**:
  - If `count_unit` is `"chapter"` and `count_threshold` is `2`, the text will be split every two occurrences of the word `"chapter"`.

### Overlap (`overlap`)

- Number of characters or units reused between consecutive chunks.
- Helps maintain context between consecutive parts of the text.
- **Example**:
  - An `overlap` of `150` reuses the last 150 characters of the previous chunk in the next one.

---

## Practical Examples

### Example 1: Splitting by Keywords

**Text**:
```plaintext
Chapter 1: Introduction. Chapter 2: Development. Chapter 3: Conclusion.
```

**Configuration**:
- Count unit (`count_unit`): `"Chapter"`
- Threshold (`count_threshold`): `1`
- Overlap (`overlap`): `10`

**Code**:
```python
from pureai import ChunkCount

chunk_count = ChunkCount(overlap=10, count_unit="Chapter", count_threshold=1)

data = [{"metadata": {"title": "Book"}, "page_content": text}]
documents = chunk_count.process_documents(data, max_workers=4)

for doc in documents:
    print(doc)
```

**Output**:
```plaintext
Document(metadata={'title': 'Book'}, page_content='Chapter 1: Introduction. ')
Document(metadata={'title': 'Book'}, page_content='ction. Chapter 2: Development. ')
Document(metadata={'title': 'Book'}, page_content='ment. Chapter 3: Conclusion.')
```

---

### Example 2: Splitting by Sentences

**Text**:
```plaintext
This is the first sentence. This is the second sentence. This is the third sentence.
```

**Configuration**:
- Count unit (`count_unit`): `"."` (period)
- Threshold (`count_threshold`): `1`
- Overlap (`overlap`): `5`

**Code**:
```python
chunk_count = ChunkCount(overlap=5, count_unit=".", count_threshold=1)

data = [{"metadata": {"category": "example"}, "page_content": text}]
documents = chunk_count.process_documents(data)

for doc in documents:
    print(doc)
```

**Output**:
```plaintext
Document(metadata={'category': 'example'}, page_content='This is the first sentence. ')
Document(metadata={'category': 'example'}, page_content='ence. This is the second sentence. ')
Document(metadata={'category': 'example'}, page_content='ence. This is the third sentence.')
```

---

### Example 3: Splitting by Paragraphs

**Text**:
```plaintext
Paragraph 1: Introduction to the topic.
Paragraph 2: Development of the argument.
Paragraph 3: Final conclusion.
```

**Configuration**:
- Count unit (`count_unit`): `"\n"` (newline)
- Threshold (`count_threshold`): `1`
- Overlap (`overlap`): `0`

**Code**:
```python
chunk_count = ChunkCount(overlap=0, count_unit="\n", count_threshold=1)

data = [{"metadata": {"type": "document"}, "page_content": text}]
documents = chunk_count.process_documents(data)

for doc in documents:
    print(doc)
```

**Output**:
```plaintext
Document(metadata={'type': 'document'}, page_content='Paragraph 1: Introduction to the topic.
')
Document(metadata={'type': 'document'}, page_content='Paragraph 2: Development of the argument.
')
Document(metadata={'type': 'document'}, page_content='Paragraph 3: Final conclusion.')
```

---

### Example 4: Splitting by Specific Words

**Text**:
```plaintext
Apple is a famous company. Apple develops iPhones. Apple also works with services.
```

**Configuration**:
- Count unit (`count_unit`): `"Apple"`
- Threshold (`count_threshold`): `2`
- Overlap (`overlap`): `20`

**Code**:
```python
chunk_count = ChunkCount(overlap=20, count_unit="Apple", count_threshold=2)

data = [{"metadata": {"company": "tech"}, "page_content": text}]
documents = chunk_count.process_documents(data)

for doc in documents:
    print(doc)
```

**Output**:
```plaintext
Document(metadata={'company': 'tech'}, page_content='Apple is a famous company. Apple develops iPhones. ')
Document(metadata={'company': 'tech'}, page_content=' iPhones. Apple also works with services.')
```

---

## Practical Applications

- **Text pre-processing for language models**.
- **Segmenting long documents** into smaller parts for analysis.
- **Maintaining context** in processing pipelines.



