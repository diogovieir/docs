---
title: 'PureRouter Python SDK'
description: 'Complete guide to using the PureRouter Python SDK'
---

# PureRouter Python SDK

<Note>
PureRouter is a completely independent product from PureCPP. You can use PureRouter without needing PureCPP and vice versa.
</Note>

## Installation

To start using the PureRouter Python SDK, install it via pip:

```bash
pip install purerouter
```

## Configuration

Import and configure the PureRouter client:

```python
from purerouter import PureRouter
from purerouter.types import InferRequest, InvokeRequest

# Initialize the client with your API key
client = PureRouter(router_key="your-api-key-here")
```

## Query Routing

### Using Routing Profiles

PureRouter offers three main routing profiles:

```python
# Economy profile - cost-optimized
resp_economy = client.router.infer(InferRequest(
    prompt="What is the capital of Brazil?", 
    profile="economy"
))
print(resp_economy.output_text)

# Balanced profile - balance between cost and quality
resp_balanced = client.router.infer(InferRequest(
    prompt="Explain the theory of relativity", 
    profile="balanced"
))
print(resp_balanced.output_text)

# Quality profile - prioritizes response quality
resp_quality = client.router.infer(InferRequest(
    prompt="Write a poem about artificial intelligence", 
    profile="quality"
))
print(resp_quality.output_text)
```

### Direct Deployment Calls

You can also directly call a specific model using its deployment ID:

```python
# Direct call to a specific model
response = client.deployments.invoke(
    "ca10db2f-364e-55dc-9d0f-b56e36f1140f",  # Deployment ID
    InvokeRequest(
        messages=[{"role": "user", "content": "Hello, how can I help?"}],
        parameters={"temperature": 0.7}
    )
)
print(response)
```

## Advanced Parameters

### Inference Parameter Configuration

```python
# Configuring additional parameters
response = client.router.infer(InferRequest(
    prompt="Summarize this text: " + long_text,
    profile="balanced",
    parameters={
        "temperature": 0.3,  # Controls response randomness
        "max_tokens": 500,  # Limits response size
        # Other model-specific parameters
    }
))
```

### Response Streaming

```python
# Getting streaming responses
for chunk in client.router.infer_stream(InferRequest(
    prompt="Tell a long story",
    profile="quality"
)):    print(chunk.output_text, end="", flush=True)
```

## Error Handling

```python
try:
    response = client.router.infer(InferRequest(
        prompt="What is the answer to life, the universe, and everything?",
        profile="economy"
    ))
    print(response.output_text)
except Exception as e:
    print(f"Error making request: {e}")
```

## Complete Examples

### Question and Answer Assistant

```python
from purerouter import PureRouter
from purerouter.types import InferRequest

client = PureRouter(router_key="your-api-key-here")

def qa_assistant():
    print("PureRouter Assistant - Type 'exit' to quit")
    
    while True:
        question = input("\nYour question: ")
        if question.lower() == "exit":
            break
            
        try:
            # Use balanced profile for balance between cost and quality
            response = client.router.infer(InferRequest(
                prompt=question,
                profile="balanced"
            ))
            print(f"\nAnswer: {response.output_text}")
        except Exception as e:
            print(f"\nError: {e}")

if __name__ == "__main__":
    qa_assistant()
```

## Next Steps

<CardGroup>
  <Card title="API Reference" icon="code" href="/purerouter/api/reference">
    Check the complete API endpoints documentation
  </Card>
  
  <Card title="Routing Profiles" icon="route" href="/purerouter/guides/routing-profiles">
    Learn more about economy, balanced, and quality profiles
  </Card>
  
  <Card title="Deployments" icon="server" href="/purerouter/guides/deployments">
    Learn to deploy open source models and use them via API
  </Card>
</CardGroup>